{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuroevolution: Exercise 6\n",
    "=========\n",
    "###### Artur Ganzha 10019651\n",
    "---------\t\n",
    "###### Raul Gorek 10061333\n",
    "---------\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "### NeuralNet\n",
    "def derivative_bcel(prediction, ground_truth):\n",
    "    x =  np.where(ground_truth == 0, 1.0 / (1.0 - prediction), -1.0 / prediction)\n",
    "    return x\n",
    "\n",
    "def derivative_mse(prediction, ground_truth):\n",
    "    batch_size = ground_truth.shape[0]\n",
    "    return -2 * (ground_truth - prediction) / batch_size\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.W = np.random.uniform(-1, 1,(self.input_size,self.output_size))\n",
    "        self.B = np.zeros((1, self.output_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.fw = x\n",
    "        return np.dot(x, self.W) + self.B\n",
    "    \n",
    "    def backward(self, d, lr):\n",
    "        d_w = np.dot(self.fw.T, d)\n",
    "        d_e = np.dot(d, self.W.T)\n",
    "        d_b = np.sum(d, axis=0, keepdims=True)\n",
    "        self.W -= lr * d_w / self.fw.shape[0]\n",
    "        self.B -= lr * d_b / self.fw.shape[0]\n",
    "        return d_e\n",
    "\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.fw = x\n",
    "        return x * (x > 0)\n",
    "    \n",
    "    def backward(self, d, lr):\n",
    "        return d * np.where(self.fw > 0, 1.0, 0.0)\n",
    "    \n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.fw = x\n",
    "        self.out = 1.0 / (1.0 + np.exp(-x))\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, d, lr):\n",
    "        return d * (self.out * (1.0 - self.out))\n",
    "    \n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers: list):\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward_pass(self, deriv, lr):\n",
    "        for layer in reversed(self.layers):\n",
    "            deriv = layer.backward(deriv, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class Indiviuum:\n",
    "    def __init__(self, n_obs, n_act):\n",
    "        self.net = NeuralNetwork([\n",
    "            Linear(n_obs, 32), ReLU(),\n",
    "            Linear(32, 32), ReLU(),\n",
    "            Linear(32, n_act)\n",
    "        ])\n",
    "        self.fitness = -np.inf\n",
    "\n",
    "    def mutate(self, rate):\n",
    "        if np.random.random() < rate:\n",
    "            for layer in self.net.layers:\n",
    "                if type(layer) == Linear:\n",
    "                    layer.W += np.random.normal(0,1,size=layer.W.shape)\n",
    "                    layer.B += np.random.normal(0,1,size=layer.B.shape)\n",
    "\n",
    "    def eval(self, func: callable):\n",
    "        self.fitness = func(self)\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "num_actions = env.action_space.n\n",
    "obs_shape = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EVAL_FIT = 5\n",
    "MAX_TIME_BUDGET = 5\n",
    "def fitness(ind: Indiviuum):\n",
    "    rewards = np.zeros((NUM_EVAL_FIT,))\n",
    "    for i in range(NUM_EVAL_FIT):\n",
    "        end = False\n",
    "        obs, _ = env.reset()\n",
    "        t_start = time.perf_counter()\n",
    "        while not end or time.perf_counter() - t_start > MAX_TIME_BUDGET:\n",
    "            action = np.argmax(ind.net.forward_pass(obs))\n",
    "            obs, r, ter, trunc, _ = env.step(action)\n",
    "            rewards[i] += r\n",
    "            end = ter or trunc\n",
    "    return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME_BUDGET = 5\n",
    "def run100(ind: Indiviuum):\n",
    "    return np.mean([fitness(ind) for _ in range(int(100.0 / NUM_EVAL_FIT))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warum ist es besser ein Individuum mehrmals zu testen: Da eine gewisse Zufallskomponente in dem Environment liegt, wird nicht jeder Durchlauf gleich sein. D.h. der summierte Reward folgt einer Verteilung. Daher ist es besser den Durchschnitt über ein paar wenige Durchläufe zu nehmen (bei zu vielen Durchläufen könnte es strärker auf die Rechenzeit gehen.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "ind = Indiviuum(obs_shape, num_actions)\n",
    "ind.eval(fitness)\n",
    "print(ind.fitness)\n",
    "ind2 = ind.copy()\n",
    "print(ind2.fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(ind: Indiviuum):\n",
    "    tenv = gym.make('CartPole-v1', render_mode='human')\n",
    "    print(ind.fitness)\n",
    "    obs, _ = tenv.reset()\n",
    "    end = False\n",
    "    while not end:\n",
    "        tenv.render()\n",
    "        action = np.argmax(ind.net.forward_pass(obs))\n",
    "        obs, _, ter, trunc, _ = tenv.step(action)\n",
    "        end = ter or trunc\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mit Elitist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 100\n",
    "MAX_GEN = 200\n",
    "SELECTION_SIZE = 20\n",
    "MUT_RATE_DECAY = 0.9\n",
    "\n",
    "def EA_elite():\n",
    "    # Init\n",
    "    population = [Indiviuum(obs_shape, num_actions) for _ in range(POP_SIZE)]\n",
    "    mr = 1.0\n",
    "    # Check terminal\n",
    "    generation = 0\n",
    "    max_f = 0\n",
    "    while generation < MAX_GEN and max_f < 475:\n",
    "        # Selection\n",
    "        for ind in population: ind.eval(fitness)\n",
    "        population = sorted(population, key=lambda x: x.fitness, reverse=True)\n",
    "        selected = population[:SELECTION_SIZE]\n",
    "        max_f = run100(selected[0])\n",
    "        print(f\"Generation: {generation+1} Max fitness over 100 runs: {max_f}\")\n",
    "        # Mutation\n",
    "        mutated = []\n",
    "        i = 0\n",
    "        while len(mutated) < POP_SIZE - SELECTION_SIZE:\n",
    "            copied = selected[i].copy()\n",
    "            copied.mutate(mr)\n",
    "            mutated.append(copied)\n",
    "        \n",
    "        population = selected + mutated\n",
    "        generation += 1\n",
    "    mr *= MUT_RATE_DECAY\n",
    "\n",
    "    for ind in population: ind.eval(fitness)\n",
    "    population = sorted(population, key=lambda x: x.fitness, reverse=True)\n",
    "    return population[0], generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 100\n",
    "MAX_GEN = 200\n",
    "SELECTION_SIZE = 20\n",
    "MUT_RATE_DECAY = 0.9\n",
    "\n",
    "def EA_prop():\n",
    "    # Init\n",
    "    population = [Indiviuum(obs_shape, num_actions) for _ in range(POP_SIZE)]\n",
    "    mr = 1.0\n",
    "    # Check terminal\n",
    "    generation = 0\n",
    "    max_f = 0\n",
    "    while generation < MAX_GEN and max_f < 475:\n",
    "        # Selection\n",
    "        for ind in population: ind.eval(fitness)\n",
    "        population = sorted(population, key=lambda x: x.fitness, reverse=True)\n",
    "        f = np.array([i.fitness for i in population])\n",
    "        selected = list(np.random.choice(population, size=(SELECTION_SIZE,), p=f/f.sum(), replace=False))\n",
    "        selected = sorted(selected, key=lambda x: x.fitness, reverse=True)\n",
    "        max_f = run100(selected[0])\n",
    "        print(f\"Generation: {generation+1} Max fitness over 100 runs: {max_f}\")\n",
    "        # Mutation\n",
    "        mutated = []\n",
    "        i = 0\n",
    "        while len(mutated) < POP_SIZE - SELECTION_SIZE:\n",
    "            copied = selected[i].copy()\n",
    "            copied.mutate(mr)\n",
    "            mutated.append(copied)\n",
    "        \n",
    "        population = selected + mutated\n",
    "        generation += 1\n",
    "    mr *= MUT_RATE_DECAY\n",
    "\n",
    "    for ind in population: ind.eval(fitness)\n",
    "    population = sorted(population, key=lambda x: x.fitness, reverse=True)\n",
    "    return population[0], generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 1 Max fitness over 100 runs: 226.41\n",
      "Generation: 2 Max fitness over 100 runs: 498.55\n",
      "Mean of 100 runs: 500.0\n",
      "500.0\n"
     ]
    }
   ],
   "source": [
    "best, _ = EA_elite()\n",
    "f100 = run100(best)\n",
    "print(f'Mean of 100 runs: {f100}')\n",
    "render(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 1 Max fitness over 100 runs: 366.68999999999994\n",
      "Generation: 2 Max fitness over 100 runs: 383.13\n",
      "Generation: 3 Max fitness over 100 runs: 370.25\n",
      "Generation: 4 Max fitness over 100 runs: 162.59999999999997\n",
      "Generation: 5 Max fitness over 100 runs: 253.61999999999998\n",
      "Generation: 6 Max fitness over 100 runs: 274.43999999999994\n",
      "Generation: 7 Max fitness over 100 runs: 267.25000000000006\n",
      "Generation: 8 Max fitness over 100 runs: 278.63999999999993\n",
      "Generation: 9 Max fitness over 100 runs: 263.06\n",
      "Generation: 10 Max fitness over 100 runs: 280.85\n",
      "Generation: 11 Max fitness over 100 runs: 473.66\n",
      "Generation: 12 Max fitness over 100 runs: 472.51000000000005\n",
      "Generation: 13 Max fitness over 100 runs: 478.36\n",
      "Mean of 100 runs: 498.57\n",
      "500.0\n"
     ]
    }
   ],
   "source": [
    "best, _ = EA_prop()\n",
    "f100 = run100(best)\n",
    "print(f'Mean of 100 runs: {f100}')\n",
    "render(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "Durchschnittliche Generationen Elitist: 10.98\n",
      "Durchschnittliche Generationen Proportional: 11.04\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "NUM = 100\n",
    "genmeanprop = np.zeros((NUM,))\n",
    "genmeanelite = np.zeros((NUM,))\n",
    "for i in range(NUM):\n",
    "    _, genp = EA_prop()\n",
    "    _, gene = EA_elite()\n",
    "    genmeanprop[i] = genp\n",
    "    genmeanelite[i] = gene\n",
    "    clear_output(wait=True)\n",
    "    print(i)\n",
    "\n",
    "print(f'Durchschnittliche Generationen Elitist: {np.mean(genmeanelite)}')\n",
    "print(f'Durchschnittliche Generationen Proportional: {np.mean(genmeanprop)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den Experimenten zeigt sich, dass elitist selection ein mini bisschen besser funktioniert, als Fitness proportional selection. Aber beides kovergiert im Durchschnitt nach 11 Generationen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
